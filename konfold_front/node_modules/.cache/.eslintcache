[{"/Users/hayungyoo/project/konfold_front/src/index.js":"1","/Users/hayungyoo/project/konfold_front/src/App.js":"2","/Users/hayungyoo/project/konfold_front/src/pages/NavBar.js":"3","/Users/hayungyoo/project/konfold_front/src/pages/Search.js":"4","/Users/hayungyoo/project/konfold_front/src/pages/AlphaFold.js":"5","/Users/hayungyoo/project/konfold_front/src/pages/Reference/Pred_ability.jsx":"6","/Users/hayungyoo/project/konfold_front/src/AFoutput.jsx":"7","/Users/hayungyoo/project/konfold_front/src/pages/AlphaOutput.jsx":"8","/Users/hayungyoo/project/konfold_front/src/pages/About.jsx":"9","/Users/hayungyoo/project/konfold_front/src/pages/Home.jsx":"10","/Users/hayungyoo/project/konfold_front/src/pages/Reference/HowAlpha.jsx":"11","/Users/hayungyoo/project/konfold_front/src/pages/Reference/Pred_mech.jsx":"12","/Users/hayungyoo/project/konfold_front/src/pages/Reference/Prediction.jsx":"13","/Users/hayungyoo/project/konfold_front/src/pages/Reference/HowRoseta.jsx":"14","/Users/hayungyoo/project/konfold_front/src/pages/Reference/Pred_skills.jsx":"15","/Users/hayungyoo/project/konfold_front/src/pages/Reference/NavBar_Prediction.js":"16"},{"size":282,"mtime":1684700574000,"results":"17","hashOfConfig":"18"},{"size":1769,"mtime":1685281732968,"results":"19","hashOfConfig":"18"},{"size":1620,"mtime":1685328028813,"results":"20","hashOfConfig":"18"},{"size":4830,"mtime":1686144911343,"results":"21","hashOfConfig":"18"},{"size":7201,"mtime":1686144953869,"results":"22","hashOfConfig":"18"},{"size":750,"mtime":1684700574000,"results":"23","hashOfConfig":"18"},{"size":1690,"mtime":1686144289644,"results":"24","hashOfConfig":"18"},{"size":2388,"mtime":1686104460387,"results":"25","hashOfConfig":"18"},{"size":4257,"mtime":1686143268051,"results":"26","hashOfConfig":"18"},{"size":921,"mtime":1684700574000,"results":"27","hashOfConfig":"18"},{"size":10891,"mtime":1684840341348,"results":"28","hashOfConfig":"18"},{"size":8989,"mtime":1684700574000,"results":"29","hashOfConfig":"18"},{"size":4559,"mtime":1684700574000,"results":"30","hashOfConfig":"18"},{"size":7887,"mtime":1684842578346,"results":"31","hashOfConfig":"18"},{"size":4722,"mtime":1684700574000,"results":"32","hashOfConfig":"18"},{"size":1025,"mtime":1684700574000,"results":"33","hashOfConfig":"18"},{"filePath":"34","messages":"35","suppressedMessages":"36","errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"37"},"fc9wkz",{"filePath":"38","messages":"39","suppressedMessages":"40","errorCount":0,"fatalErrorCount":0,"warningCount":4,"fixableErrorCount":0,"fixableWarningCount":0,"source":"41","usedDeprecatedRules":"37"},{"filePath":"42","messages":"43","suppressedMessages":"44","errorCount":0,"fatalErrorCount":0,"warningCount":3,"fixableErrorCount":0,"fixableWarningCount":0,"source":"45","usedDeprecatedRules":"37"},{"filePath":"46","messages":"47","suppressedMessages":"48","errorCount":0,"fatalErrorCount":0,"warningCount":5,"fixableErrorCount":0,"fixableWarningCount":0,"source":null},{"filePath":"49","messages":"50","suppressedMessages":"51","errorCount":0,"fatalErrorCount":0,"warningCount":3,"fixableErrorCount":0,"fixableWarningCount":0,"source":null},{"filePath":"52","messages":"53","suppressedMessages":"54","errorCount":0,"fatalErrorCount":0,"warningCount":7,"fixableErrorCount":0,"fixableWarningCount":0,"source":"55","usedDeprecatedRules":"37"},{"filePath":"56","messages":"57","suppressedMessages":"58","errorCount":0,"fatalErrorCount":0,"warningCount":6,"fixableErrorCount":0,"fixableWarningCount":0,"source":null},{"filePath":"59","messages":"60","suppressedMessages":"61","errorCount":0,"fatalErrorCount":0,"warningCount":5,"fixableErrorCount":0,"fixableWarningCount":0,"source":null},{"filePath":"62","messages":"63","suppressedMessages":"64","errorCount":0,"fatalErrorCount":0,"warningCount":5,"fixableErrorCount":0,"fixableWarningCount":0,"source":null},{"filePath":"65","messages":"66","suppressedMessages":"67","errorCount":0,"fatalErrorCount":0,"warningCount":7,"fixableErrorCount":0,"fixableWarningCount":0,"source":"68","usedDeprecatedRules":"37"},{"filePath":"69","messages":"70","suppressedMessages":"71","errorCount":0,"fatalErrorCount":0,"warningCount":16,"fixableErrorCount":0,"fixableWarningCount":0,"source":"72","usedDeprecatedRules":"37"},{"filePath":"73","messages":"74","suppressedMessages":"75","errorCount":0,"fatalErrorCount":0,"warningCount":3,"fixableErrorCount":0,"fixableWarningCount":0,"source":"76","usedDeprecatedRules":"37"},{"filePath":"77","messages":"78","suppressedMessages":"79","errorCount":0,"fatalErrorCount":0,"warningCount":5,"fixableErrorCount":0,"fixableWarningCount":0,"source":"80","usedDeprecatedRules":"37"},{"filePath":"81","messages":"82","suppressedMessages":"83","errorCount":0,"fatalErrorCount":0,"warningCount":10,"fixableErrorCount":0,"fixableWarningCount":0,"source":"84","usedDeprecatedRules":"37"},{"filePath":"85","messages":"86","suppressedMessages":"87","errorCount":0,"fatalErrorCount":0,"warningCount":6,"fixableErrorCount":0,"fixableWarningCount":0,"source":"88","usedDeprecatedRules":"37"},{"filePath":"89","messages":"90","suppressedMessages":"91","errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"92","usedDeprecatedRules":"37"},"/Users/hayungyoo/project/konfold_front/src/index.js",[],[],[],"/Users/hayungyoo/project/konfold_front/src/App.js",["93","94","95","96"],[],"import React, { Component } from 'react';\nimport { BrowserRouter,Route, Routes } from \"react-router-dom\";\nimport AFoutput from \"./AFoutput\";\nimport Navbar from \"./pages/NavBar\";\nimport About from \"./pages/About\";\nimport Search from \"./pages/Search\";\nimport Home from \"./pages/Home\";\nimport HowAlpha from \"./pages/Reference/HowAlpha\";\nimport HowRoseta from \"./pages/Reference/HowRoseta\";\nimport Prediction from \"./pages/Reference/Prediction\";\nimport Pred_mech from \"./pages/Reference/Pred_mech\";\nimport Pred_skills from \"./pages/Reference/Pred_skills\";\nimport Pred_ability from \"./pages/Reference/Pred_ability.jsx\";\nimport AlphaFold from \"./pages/AlphaFold\";\nimport AlphaOutput from \"./pages/AlphaOutput\";\n\n\n\nfunction App() {\n  //console.log(window.location.pathname)\n  return (\n    \n    <BrowserRouter>\n      <div >\n      <Navbar/>\n        <Routes>\n        \n          <Route path=\"/\" element={ <Home/> } />\n          <Route path=\"/proteinInput/*\" element={ <AFoutput/> } />\n          <Route path=\"/Search/*\" element={  <Search/> } />\n          <Route path=\"/AlphaFold/*\" element={  <AlphaFold/> } />\n          <Route path=\"/AlphaOutput/*\" element={  <AlphaOutput/> } />\n          <Route path=\"/About/*\" element={  <About/> } />\n          <Route path=\"/Refer/Prediction/*\" element ={ <Prediction/>} />\n          <Route path=\"/Refer/Prediction/mechanism/*\" element ={ <Pred_mech/>} />\n          <Route path=\"/Refer/Prediction/ability/*\" element ={ <Pred_ability/>} />\n          <Route path=\"/Refer/Prediction/skills/*\" element ={ <Pred_skills/>} />\n          <Route path=\"/Refer/HowAlpha/*\" element ={ <HowAlpha/>} />\n          <Route path=\"/Refer/HowRoseta/*\" element ={ <HowRoseta/>} />\n\n        </Routes>\n      </div>\n    </BrowserRouter>\n  );  \n}\n\nexport default App;","/Users/hayungyoo/project/konfold_front/src/pages/NavBar.js",["97","98","99"],[],"import React, { useState } from 'react';\n\n\n\nconst Navbar = () => {\n    const menuLst = [\"Search\", \"About\", \"Refer\"];\n    const [hide, setHide] = useState(true);\n    \n    const mouseEvent = ( bool) => {\n        const change = { ...hide };\n        change= bool;\n        setHide(change);\n    };\n\n    \n    \n\n    return (\n        <nav className=\"nav\">\n            {/* Home 제목 */}\n        <a href=\"/\" className=\"site-title\">\n            Konfold\n        </a>\n        {/* 대 메뉴  */}\n        \n        <ul className=\"navContainer\">\n            <li>\n                <a href=\"/AlphaFold\">AlphaFold</a>\n            </li>\n       \n            \n            <li>\n                <a href=\"/Search\">Search</a>\n            </li>\n            <li>\n                <a href=\"/About\">People</a>\n            </li>\n            \n            <li  className={hide ? \"active\" : \"none\"}\n            onMouseLeave={() => setHide(true)}\n            onMouseEnter={() => setHide(false)}\n            >\n                {hide && (<p className='ref'>{`Reference`}</p>)}\n                \n                {!hide && (<div className='refer-menu'>\n        \n          \n                <li >\n                    \n                    <a href=\"/Refer/Prediction/*\">Prediction</a>\n                </li>\n                <li>\n                    <a href=\"/Refer/HowAlpha/*\">HowAlpha</a>\n                </li>\n                <li>\n                    <a href=\"/Refer/HowRoseta/*\">HowRoseta</a>\n                </li>\n\n\n                        </div>)}\n            </li>\n        \n        </ul>\n        \n        \n        \n    </nav>\n    );\n};\n\nexport default Navbar;\n\n","/Users/hayungyoo/project/konfold_front/src/pages/Search.js",["100","101","102","103","104"],[],"/Users/hayungyoo/project/konfold_front/src/pages/AlphaFold.js",["105","106","107"],[],"/Users/hayungyoo/project/konfold_front/src/pages/Reference/Pred_ability.jsx",["108","109","110","111","112","113","114"],[],"import React, { useEffect, useState } from \"react\";\nimport axios from \"axios\";\nimport { Link } from \"react-router-dom\";\nimport styled from 'styled-components';\nimport NavBar_Prediction from './NavBar_Prediction.js';\n\n\nexport default function Pred_ability() {\n    const Wrap = styled.div`\n    display: flex;\n    flex-direction: row;\n    background: #f7f7f7 ;\n    max-width: 80%;\n    margin: 0 auto;\n    `;\n    function Span({ space = 20 }){\n\treturn (\n    \t<span style={{ paddingRight: space }}></span>\n    );\n}\n\n    return (\n        <div className=\"prediction_page\">\n            <NavBar_Prediction/>\n            \n            <div className=\"firstImg\">\n      <img className=\"AboutImg\" alt=\"role\" src=\"/img/role.png\" />\n    </div>\n        </div>\n    )\n}","/Users/hayungyoo/project/konfold_front/src/AFoutput.jsx",["115","116","117","118","119","120"],[],"/Users/hayungyoo/project/konfold_front/src/pages/AlphaOutput.jsx",["121","122","123","124","125"],[],"/Users/hayungyoo/project/konfold_front/src/pages/About.jsx",["126","127","128","129","130"],[],"/Users/hayungyoo/project/konfold_front/src/pages/Home.jsx",["131","132","133","134","135","136","137"],[],"import React, { useEffect, useState } from \"react\";\nimport axios from \"axios\";\nimport { Link } from \"react-router-dom\";\nimport styled, { keyframes } from \"styled-components\";\n\nexport default function Home() {\n  //return <div className=\"WordHome\">Home</div>;\n  return (\n    <div className=\"HomeImg\">\n      <img className=\"ProteinImg\" src=\"/img/proteinImg.png\" />\n      <h1 className=\"Site-explaining\">\n        본 웹사이트는\n        <br />\n        <br />\n        건국대학교 졸업 프로젝트를 위해\n        <br />\n        <br />\n        제작되었습니다.\n      </h1>\n      <script>IntersectionObserver()</script>\n    </div>\n    // <Wrapper>\n    //   <Box>\n    //     <span>\n    //       본 웹사이트는\n    //       <br />\n    //       건국대학교 졸업 프로젝트를 위해\n    //       <br />\n    //       제작되었습니다.\n    //     </span>\n    //   </Box>\n    // </Wrapper>\n  );\n}\n","/Users/hayungyoo/project/konfold_front/src/pages/Reference/HowAlpha.jsx",["138","139","140","141","142","143","144","145","146","147","148","149","150","151","152","153"],[],"import React, { useEffect, useState } from \"react\";\nimport axios from \"axios\";\nimport { Link } from \"react-router-dom\";\nimport styled from 'styled-components';\n\nexport default function HowAlpha() {\n  const Wrap = styled.div`\n  display: flex;\n  flex-direction: row;\n  background: #f7f7f7 ;\n  max-width: 80%;\n  margin: 0 auto;\n`;\nfunction Span({ space = 20 }){\n\treturn (\n    \t<span style={{ paddingRight: space }}></span>\n    );\n}\n\n\n  return (\n    <div className=\"prediction_page\">\n      <h1 className=\"refer-title\">\n        사용법\n        </h1>\n        <h1 className=\"title-N1\">\n        1. AlphaFold2 (Ubuntu 22.04)\n      </h1>\n      <h1 className=\"title-N1\">\n        (1) AlphaFold(.git) cloning\n      </h1>\n      <h1 className=\"korean-protein-expaination\">\n      git(프로그래밍 코드 버전 관리 프로그램) 설치\t\n       </h1>\n       <div className=\"code_page\">\n       $ which git\t\t//git 설치여부 확인\n        <Span></Span>\n        $ sudo apt install git\t//git 설치\n       </div>\n       <h1 className=\"korean-protein-expaination\">\n       AlphaFold 클로닝\n       </h1>\n       <div className=\"code_page\">\n       $ mkdir /[filename]\n       <Span></Span>\n       $ cd /[filename]\t\t//AlphaFold2 git를 저장하고자 하는 폴더에 접속\n       <Span></Span>\n       $ git clone https://github.com/deepmind/alphafold.git\n\n       </div>\n       <h1 className=\"title-N1\">\n        (2) Database\n      </h1>\n      <h1 className=\"korean-protein-expaination\">\n      Aria2(다중서버 명령 줄 다운로드 유틸리티) 설치\n       </h1>\n       <div className=\"code_page\">\n       $ which aria2c\t\t//aria2 설치여부 확인\n       <Span></Span>\n       $ sudo apt install aria2\t//aria2 설치\n       </div>\n       <h1 className=\"korean-protein-expaination\">\n       Alphafold/scripts 속 파일을 불러와 database를 다운로드(코드 수정 시 선택적으로 다운로드 가능)\n       </h1>\n       <div className=\"code_page\">\n       $ cd /[filename]/alphafold\t //alphafold가 클로닝된 폴더로 접속\n       <Span></Span>\n       //alphafold와 다른 폴더에 저장하는 것이 좋음\n       <Span></Span>\n       //reduced_dbs는 용량 작은 버전\n       <Span></Span>\n       $ sudo scripts/download_all_data.sh /[filename]/db/ reduced_dbs\n\n       </div>\n       <h1 className=\"title-N1\">\n        (3) Docker\n      </h1>\n      <div className=\"code_page\">\n      //docker repository를 사용할 수 있게 필수 패키지 설치\n      <Span></Span>\n      $ sudo apt install apt-transport-https ca-certifiates curl gnupg lsb-release\t\n      <Span></Span>\n      //docker와 암호화 통신을 위한 GPG keyrings 추가\n      <Span></Span>\n      $ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dreamor -o /usr/share/keyrings/docker-archive-keyring.gpg\n      <Span></Span>\n      //설치할 시스템에 해당하는 docker repository를 추가 후 apt update\n      <Span></Span>\n      $echo \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list 여기 /dev/null\n      <Span></Span>\n      $ sudo apt update\n      <Span></Span>\n      //docker-ce, docker-ce-cli, containerd.io 설치\n      <Span></Span>\n      $ sudo apt install docker-ce docker-ce-cli containerd.io\n      <Span></Span>\n      //docker 설치 확인 (docker의 hello-world 실행)\n      <Span></Span>\n      $ sudo docker run hello-world\n      <Span></Span>\n      $ sudo apt update\t//설치 가능한 도구들의 목록을 갱신\n\n       </div>\n       <h1 className=\"korean-protein-expaination\">\n       (참고) apt list\n       </h1>\n       <h1 className=\"korean-protein-expaination\">\n       Apt list에 기록된 저장소(repository)들이 apt update 시 자동으로 업데이트 된다.\n       </h1>\n       <h1 className=\"korean-protein-expaination\">\n       /etc/apt/sources.list에서 확인 가능하며, vi 편집기 (vi/etc/apt/sources.list)로 편집가능하다.\n       </h1>\n       <h1 className=\"korean-protein-expaination\">\n       docker를 사용할 수 있는 사용자(현재 컴퓨터의 사용자 계정)를 추가\n       </h1>\n       <div className=\"code_page\">\n       $ sudo groupadd docker\t\t\t//사용자 그룹에 docker 추가\n       <Span></Span>\n       $ sudo usermod -aG docker $USER\t//현재 사용자 계정을 docker 사용자 그룹에 추가\n       <Span></Span>\n       $ newgrp docker\t\t\t//계정 로그아웃 후 재로그인\n       <Span></Span>\n       //일반 사용자로서 도커 사용가능여부 확인 (docker의 hello-world 실행)\n       <Span></Span>\n       $ docker run hello-world\n\n       </div>\n       <h1 className=\"title-N1\">\n        (4) 그래픽 처리 장치 (GPU) 드라이버 구성\n      </h1>\n      <h1 className=\"korean-protein-expaination\">\n      GPU 사용 가능 여부 확인 (GPU 목록이 표시되지 않은 경우 다음의 과정을 따른다.)\n       </h1>\n       <div className=\"code_page\">\n       $ docker run --gpus all nvidia/cuda:11.5.2-base-ubuntu20.04 nvidia-smi\n       </div>\n       <h1 className=\"korean-protein-expaination\">\n       사용가능한 GPU 확인\n       </h1>\n       <div className=\"code_page\">\n       $ sudo update-pciids\n       <Span></Span>$ lspci | grep VGA\n      <Span></Span>예시 결과: [Geforce RTX 3070 Ti Laptop GPU]\n       </div>\n       <h1 className=\"korean-protein-expaination\">\n       GPU에 알맞은 nvidia driver 설치\n       </h1>\n       <div className=\"code_page\">\n       //설치가능한 드라이버 확인 \n       <Span></Span>$ ubuntu-drivers devices\n       <Span></Span>//(방법1)원하는 버전 수동설치 \n       <Span></Span>$ sudo apt install nvidia-driver-525\n       <Span></Span>//(방법2)드라이버직접다운(nvidia 웹페이지에서 파일 다운로드)\n       <Span></Span>$ sudo sh NVIDIA-Linux-x86_64-525.105.17.run \n       <Span></Span>$ which nvidia-smi\t// nvidia driver 설치여부 확인\n       <Span></Span>$ nvidia-smi\t\t// 설치된 nvidia GPU 확인\n       </div>\n       <h1 className=\"korean-protein-expaination\">\n       GPU 사용을 위한 nvidia container toolkit 설치\n       </h1>\n       <div className=\"code_page\">\n       $ distribution=$(. /etc/os-release;echo $ID$VERSION_ID)\n       <Span></Span>$ curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add – \n       <Span></Span>$ curl -s -L https://nvidia.github.io/nvidia-docker/ubuntu22.04/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list\n       <Span></Span>$ sudo apt update\n       <Span></Span>$ sudo apt -y install nvidia-container-toolkit\n       <Span></Span>$ sudo systemctl restart docker\n       <Span></Span>$ docker run --gpus all nvidia/cuda:11.5.2-base-ubuntu20.04 nvidia-smi\n       </div>\n       <h1 className=\"korean-protein-expaination\">\n       GPU 사용을 위한 nvidia container toolkit 설치\n       </h1>\n       <Wrap >\n      <div>\n        <img className=\"peptide_img\" alt=\"role\" src=\"/img/HowAlpha_nvidia_gpu.png\" />\n      </div>\n      <div>\n        <img className=\"amino_img\" alt=\"role\" src=\"/img/HowAlpha_nvidia_container.png\" />\n      </div>\n      </Wrap>\n      <Wrap>\n      <hi className=\"img_title\">\n      그림 15 nvidia GPU 확인\n      </hi>\n      <Span /><Span />\n      <hi className=\"img_title\">\n         그림 16 nvidia container 확인\n         </hi>\n         </Wrap>\n\n      <h1 className=\"title-N1\">\n        (4) Alphafold docker 이미지 생성\n      </h1>\n      <h1 className=\"korean-protein-expaination\">\n      Dockerfile 코드를 실행하여 도커 이미지 생성 (alphafold 파일에 접속한 후 실행)       \n      </h1>\n      <div className=\"code_page\">\n      $ cd [filename]/alphafold\t\t//alphafold가 클로닝된 폴더로 접속\n      <Span /><Span />$ docker build -f docker/Dockerfile -t alphafold .\n      <Span /><Span />//python 환경과의 충돌 방지를 위한 python 가상환경 생성 (이미지의 요구사항을 맞춤)\n      <Span /><Span />$ sudo apt install python3-pip\t//pip3가 없는 경우 미리 설치\n      <Span /><Span />$ pip3 install -r docker/requirements.tx\n      </div>\n      <h1 className=\"title-N1\">\n        (5) Alphafold 실행\n      </h1>\n      <div className=\"code_page\">\n      $python3 docker/run_docker.py \n      <Span /><Span />--fasta_paths=input/[INPUT.fasta]\t//input파일의 경로입력: alphafold 내에 존재해야 한다.\n      <Span /><Span />--max_template_date=2023-04-30\t\n      <Span /><Span />--data_dir=/[filename]/db/\t//database파일의 경로입력\n      <Span /><Span />--model_preset=monomer\t//model\n      <Span /><Span />--db_preset=reduced_dbs \t//database\t\t\n      <Span /><Span />--output_dir=/[filename]/output/\t//output파일의 경로입력\n      </div>\n      <h1 className=\"title-N1\">\n        참고\n      </h1>\n      <h1 className=\"korean-protein-expaination\">\n      “AlphaFoldv2 open-source code”, https://github.com/deepmind/alphafold\n      </h1>\n      <h1 className=\"korean-protein-expaination\">\n      “2021-Highly accurate protein structure prediction with AlphaFold”,\nhttps://www.nature.com/articles/s41586-021-03819-2\n      </h1>\n      <h1 className=\"korean-protein-expaination\">\n      “2021-Supplementary information for: Highly accurate protein structure prediction with AlphaFold”,\nhttps://www.uvio.bio/alphafold-architecture/AlphaFold-Supplementary-Information.pdf\n      </h1>\n      <h1 className=\"korean-protein-expaination\">\n      “2022-AlphaFold Protein Structure Database: massively expanding the structural coverage of protein-sequence space with high-accuracy models”,\nhttps://academic.oup.com/nar/article/50/D1/D439/6430488?login=false\n      </h1>\n      <h1 className=\"korean-protein-expaination\">\n      “AlphaFold webpage(DeepMind)”, \nhttps://www.deepmind.com/research/highlighted-research/alphafold\n      </h1>\n      <h1 className=\"korean-protein-expaination\">\n      “[Review] AlphaFold2”, https://ocxanc.tistory.com/51\n      </h1>\n      <h1 className=\"korean-protein-expaination\">\n      “알파폴드2모델분석”, https://taehojo.github.io/alphafold/alphafold2.html\n      </h1>\n      <h1 className=\"korean-protein-expaination\">\n      “Alphfafold2 논문리뷰1[성능]”, https://happyhaelee.tistory.com/m/96\n      </h1>\n      <h1 className=\"korean-protein-expaination\">\n      “Alphfafold2 논문리뷰2[입력부분]”, https://happyhaelee.tistory.com/m/98\n      </h1>\n      <h1 className=\"korean-protein-expaination\">\n      “Alphfafold2 논문리뷰4[Evoformer-pair representation]”, https://happyhaelee.tistory.com/m/99\n      </h1>\n      <h1 className=\"korean-protein-expaination\">\n      “[초심자를 위한 생물학+정보학] 알파폴드의 설치와 사용: 깃, 도커, 그리고 엔비디아”,\nhttps://www.ibric.org/myboard/read.php?Board=news&id=337509 \n      </h1>\n\n    </div>\n  );\n}","/Users/hayungyoo/project/konfold_front/src/pages/Reference/Pred_mech.jsx",["154","155","156"],[],"import React, { useEffect, useState } from \"react\";\nimport styled from 'styled-components';\nimport NavBar_Prediction from './NavBar_Prediction.js';\n\n\nexport default function Pred_mech(){\n\n    const Wrap = styled.div`\n    display: flex;\n    flex-direction: row;\n    background: #f7f7f7 ;\n    max-width: 80%;\n    margin: 0 auto;\n    `;\n\n    \n    function Span({ space = 20 }){\n\treturn (\n    \t<span style={{ paddingRight: space }}></span>\n    );\n}\n\n    return (\n        <div className=\"prediction_page\">\n            <NavBar_Prediction/>\n            <h1 className=\"refer-title\">\n            단백질 구조 예측 AI\n            </h1>\n            <h1 className=\"title-N1\">\n            2. Alpha Fold\n            </h1>\n      <h1 className=\"korean-protein-expaination\">\n      <Span /><Span />\n      ‘Deepmind’에서 개발한 단백질 구조 예측 인공지능(AI) 프로그램\n      </h1>\n      <h1 className=\"korean-protein-expaination\">\n      <Span /><Span />\nAlphaFold는 단백질 구조예측 학술대회 CASP(Critical Assessment of Structure Prediction)에서 공개되었다. 팀에게 전달되는 아미노산 서열을 보고 해당 단백질 구조를 예측하는 방식으로, AlphaFold는 다른 팀에 비해 엄청난 정확도를 가진 예측결과를 빠르게 얻어냈다.\n      </h1>\n      <h1 className=\"korean-protein-expaination\">\n      <Span /><Span />\n      AlphaFold1(2018, CASP13 우승)\n      </h1>\n      <h1 className=\"korean-protein-expaination\">\n      <Span /><Span />\n      AlphaFold2(2020, CASP14 우승) \n      </h1>\n      <Wrap >\n      <div>\n        <img className=\"process_img\" alt=\"role\" src=\"/img/structure_prediction_precise.jpeg\" />\n      </div>\n      \n      </Wrap>\n      <Wrap>\n      <hi className=\"img_title\">\n      그림 4 단백질 구조 예측 정확도 발전 추이\n          \n        </hi>\n       \n        </Wrap>\n\n        <h1 className=\"korean-protein-expaination\">\n      <Span /><Span />\n      AlphaFold는 아미노산 사슬의 단위체인 잔기(amino acid residue) 간의 거리와 각도에 대한 정보를 추출하여 그것을 물리 시뮬레이션의 제약조건으로 사용한다. Residue는 사슬 내에서 서로 상호작용한다는 사실을 바탕으로 상호작용의 정도를 추측하는 것이다. AlphaFold1은 학습의 주요 기술로서 합성곱 신경망(CNN, Convolution Neural Network)를 이용한다. AlphaFold2는 새로 개발한 학습 모델인 트랜스포머(Transformer)를 이용하며 AlphaFold1에비해 더 많은 단백질 구조 데이터를 학습한다.\n      </h1>\n      <h1 className=\"korean-protein-expaination\">\n      <Span /><Span />\n      2022년 7월 AlphaFold2의 논문과 오픈소스, 데이터베이스가 공개되었다. 공개된 자료에 따른 AlphaFold2의 아키텍처는 다음과 같이 3단계로 구성된다.\n      </h1>\n      <hi className=\"ref_left\">\n      AlphaFold 참고자료\n        </hi>\n        \n      <hi className=\"ref_left\">\n      Website<Span /><Span />https://www.deepmind.com/research/highlighted-research/alphafold\n\n        </hi>\n        \n      <hi className=\"ref_left\">\n      Source <Span /><Span />https://github.com/deepmind/alphafold\n        </hi>\n        <hi className=\"ref_left\">\n        Paper<Span /><Span />\t“Highly accurate protein structure prediction with AlphaFold(2021)”\n        </hi>\n        <hi className=\"ref_left\">\n        <Span /><Span /><Span /><Span />\t“Supplementary information for: Highly accurate protein structure prediction with AlphaFold(2021)”\n        </hi>\n        <hi className=\"ref_left\">\n        <Span /><Span /><Span /><Span />\t“AlphaFold Protein Structure Database: massively expanding the structural coverage of protein sequence space with high-accuracy models(2022)”\n        </hi>\n        <div>\n        <img className=\"process_img\" alt=\"role\" src=\"/img/model_architecture.png\" />\n      </div>\n      <hi className=\"img_title\">\n      그림 5 AlphaFold2 model architecture\n        </hi>\n        <h1 className=\"korean-protein-expaination\">\n      1단계. Input Feature embeddings, 입력 데이터 전처리\n       </h1>\n       <h1 className=\"korean-protein-expaination\">\n       <Span /><Span />입력 데이터를 모델에서 사용할 수 있게 전처리하는 단계이다. 단백질 서열이 입력되면 데이터베이스에서 유사한 서열을 검색하여 다중서열정렬(MSA, Multiple Sequence Alignment)를 생성하고, 알려진 단백질 템플릿에서 유사한 서열을 가진 부분을 pairing한다. 그리고 이를 통합해 MSA representation과 Pair representation을 만든다. 이 과정을 여러 번 반복한 결과의 평균값을 다음단계로 내보낸다.\n       </h1>\n       <hi className=\"ref_left\">\n        <Span /><Span />\n        input: amino-acid sequence\n        </hi>\n        <hi className=\"ref_left\">\n        <Span /><Span />\t\n        output: Create the initial version of the MSA representation and pair representation\n        </hi>\n        <hi className=\"ref_left\">\n        <Span /><Span />\t\n        -Genetic database search 🡪 MSA 🡪 MSA representation (진화적 특징 반영)\n        </hi>\n        <hi className=\"ref_left\">\n        <Span /><Span />\t\n        -Amino acid paring 🡪 2차원 형태로 변환 🡪 pair representation (공간적 특징 반영)        </hi>\n        <h1 className=\"korean-protein-expaination\">\n        2단계. Evoformer, Attention 학습을 통해 전처리된 데이터에서 필요한 정보 추출\n       </h1>\n       <div>\n        <img className=\"process_img\" alt=\"role\" src=\"/img/evoformer_block.png\" />\n      </div>\n      <hi className=\"img_title\">\n      그림 6 Evofomer block\n      </hi>\n      <h1 className=\"korean-protein-expaination\">\n      주어진 MSA representation과 pair representation을 self-attention 메커니즘에 적용하여 필요한 정보만 갖도록 개선하는 단계이다. 이 단계에서는 각각의 representation이 입력되어 단백질의 공간적, 진화적 관계에 대한 직접적인 추론을 가능하게 하는 정보를 교환함으로써 반복적으로 개선된다. 그 결과 단백질 구조에 대한 2D representation을 얻게 된다. \n       </h1>\n       <hi className=\"ref_left\">\n        <Span /><Span />\t\n        input: the initial version of the MSA representation and pair representation        \n        </hi>\n        <hi className=\"ref_left\">\n        <Span /><Span />\t\n        output: the final (best version) of the MSA representation and pair representation        \n        </hi>\n        <h1 className=\"korean-protein-expaination\">\n        3단계. Structure module, 2단계에서 뽑아낸 정보를 구체적인 3차원 좌표로 처리\n         </h1>\n         <h1 className=\"korean-protein-expaination\">\n         전 단계에서 만들어진 최종 2D representation 정보를 3D 좌표로 변환하는 단계이다. 이것은 weight를 공유하는 8개의 RNN 블록에서 수행된다. 초기 3D 좌표는 단백질의 모든 잔기가 동일한 위치와 방향을 갖게 배치된다. 그리고 RNN 블록 내에서 IPA(Invariant Point Attention) 연산을 사용한 업데이트, equivariant 업데이트, 비틀림 각도를 예측하는 과정을 거쳐 최종적인 3차원 좌표를 얻게 된다. 이때 출력단계에서 예측 위치의 정확도를 계산하는 과정도 포함된다.\n         </h1>\n         <hi className=\"ref_left\">\n        <Span /><Span />\t\n        input: final of MSA representation, Pair representation (2D representation)        \n        </hi>\n        <hi className=\"ref_left\">\n        <Span /><Span />\t\n        output: rotation, translation, angle\n         </hi>\n         <hi className=\"ref_left\">\n        <Span /><Span />\t\n        - Backbone (global frame) 예측\n         </hi>\n         <hi className=\"ref_left\">\n        <Span /><Span />\t\n        - Side chain (local frame) 예측\n         </hi>\n         <hi className=\"ref_left\">\n        <Span /><Span />\t\n        - pLDDT(per-residue confidence score, 잔류물별 신뢰도 메트릭): 예측의 신뢰도 자체 판단\n         </hi>\n         <h1 className=\"title-N1\">\n         RoseTTA(Three-Track Attention)Fold\n      </h1>\n      <h1 className=\"korean-protein-expaination\">\n      ‘Baker 연구팀’에서 AlphaFold에서 영감을 얻어 개발한 단백질 구조 예측 인공지능(AI) 프로그램\nAlphaFold2의 오픈소스가 공개되기 전 Baker 연구팀은 이와 비슷한 AI 모델을 개발했으며 AlphaFold2와 거의 비슷한 성능을 나타내 이목을 끌었다.\n         </h1>\n         <div>\n        <img className=\"process_img\" alt=\"role\" src=\"/img/perform_Roseta.png\" />\n      </div>\n      <h1 className=\"korean-protein-expaination\">\n      RoseTTAFold 또한 2022년 7월 논문과 오픈소스를 공개했으며 이에 따른 메커니즘은 다음과 같다.\n      </h1>\n      <div>\n        <img className=\"process_img\" alt=\"role\" src=\"/img/roseta_mech.png\" />\n      </div>\n\n\n        </div>\n    )\n}","/Users/hayungyoo/project/konfold_front/src/pages/Reference/Prediction.jsx",["157","158","159","160","161"],[],"import React, { useEffect, useState } from \"react\";\nimport axios from \"axios\";\nimport { Link } from \"react-router-dom\";\nimport styled from 'styled-components';\nimport NavBar_Prediction from './NavBar_Prediction.js';\n\nexport default function Prediction() {\n  const Wrap = styled.div`\n  display: flex;\n  flex-direction: row;\n  background: #f7f7f7 ;\n  max-width: 80%;\n  margin: 0 auto;\n`;\nfunction Span({ space = 20 }){\n\treturn (\n    \t<span style={{ paddingRight: space }}></span>\n    );\n}\n\n  return (\n    <div className=\"prediction_page\">\n      {/* prediction 안에 메뉴 */}\n      <NavBar_Prediction/>\n\n        {/* 정식 본문 시작 */}\n      <h1 className=\"refer-title\">\n        단백질 구조 예측 AI\n      </h1>\n      <h1 className=\"title-N1\">\n        1. 단백질 구조 예측 AI의 의의\n      </h1>\n      <h1 className=\"title-N1\">\n        1-1. 단백질\n      </h1>\n      <h1 className=\"english-protein-explaination\">\n      <Span /><Span />\n      Proteins are large biomolecules and macromolecules that comprise one or more long chains of amino acid residues.(Wikipedia “Protein”)\n      </h1>\n      <h1 className=\"korean-protein-expaination\">\n      <Span /><Span />\n      단백질은 아미노산으로 구성된 생체 고분자로서, 펩타이드 결합에 의해 길게 연결된 폴리펩타이드(polypeptide) 사슬을 말한다.\n      </h1>\n      \n      \n      <Wrap >\n      <div>\n        <img className=\"peptide_img\" alt=\"role\" src=\"/img/peptide_bond.jpeg\" />\n      </div>\n      <div>\n        <img className=\"amino_img\" alt=\"role\" src=\"/img/amino_acid_residue.png\" />\n      </div>\n      </Wrap>\n      <br />\n      <Wrap>\n      <hi className=\"img_title\">\n          그림 1 펩타이드 결합  \n          \n        </hi>\n        <Span /><Span />\n        <hi className=\"img_title\">\n        \n            그림 2 amino acid residue\n        </hi>\n        </Wrap>\n        <h1 className=\"protein_kind\">\n        <Span /><Span />\n        단백질은 생명체의 몸을 구성하는 기본물질이자 세포 차원에서 이루어지는 거의 모든 생명 활동에 관여하는 매개체이다. 사람의 유전자는 생명 활동의 명령을 내리고 그것의 수행자로서 단백질을 만들어낸다. 따라서 인체 내엔 생화학 반응을 조절, 매개하는 효소단백질, 성장 및 생체 대사를 촉진하는 호르몬 단백질, 면역 조절 및 반응을 매개하는 면역단백질, 암 발병을 억제하는 암억제인자, 항체 단백질 등 다양한 종류와 기능을 가진 단백질들이 있다. \n        </h1>\n        <h1 className=\"title-N1\">\n        1-2. 단백질 구조 예측\n        </h1>\n        <h1 className=\"korean-protein-expaination\">\n      <Span /><Span />\n      단백질은 각각의 기능에 알맞은 다양한 3차원 구조를 가지고 있으며, 단백질의 아미노산 서열이 이를 결정한다. 아미노산의 유형(type)과 수(number)에 따라 사슬이 비틀리고 구부러지며 열역학적으로 가장 안정한 구조(high Energy-efficiency)를 이루게 되며 때때로 규칙에서 벗어난 단백질 구조가 존재하기도 한다. 즉, 인체는 20가지의 아미노산으로 수만~수십억가지의 다양한 단백질을 만들 수 있다.\n      </h1>\n      <div>\n        <img className=\"process_img\" alt=\"role\" src=\"/img/protein_process.png\" />\n      </div>\n      <Wrap>\n      <h1 className=\"img_title\">\n        그림 3 단백질의 형성과정\n      </h1>\n      </Wrap>\n      <h1 className=\"korean-protein-expaination\">\n      <Span /><Span />\n      단백질 구조에 이상이 생기면 질병이 발생한다. 이러한 사실은 ‘신약 개발 및 질병치료’에 있어 단백질의 구조를 규명하는 것이 큰 의의를 가지고 있음을 내포한다. 따라서 지금까지 여러 국가와 기업에서 단백질의 구조를 밝히는 실험과 연구에 막대한 비용과 시간이 투자되어왔다.\n일반적으로 단백질 구조, 즉 단백질 접힘을 예측하는 방법은 엑스선 결정학(x-ray crystallography)이나 극저온 현미경(cryo-EM, 원자수준의 정밀관찰이 가능한 현미경)을 활용한다. 그러나 이 방법은 비용과 시간(수개월~수년)이 많이 소요되며 성공확률도 매우 희박하다. 따라서 딥 러닝 알고리즘 (Deep Learning algorism)을 이용한 단백질 구조 예측 AI인 AlphaFold와 RosettaFold가 개발되었으며 실질적 사용을 위한 연구가 지속되고 있다.\n      </h1>\n      \n    </div>\n    \n    \n  );\n}","/Users/hayungyoo/project/konfold_front/src/pages/Reference/HowRoseta.jsx",["162","163","164","165","166","167","168","169","170","171"],[],"import React, { useEffect, useState } from \"react\";\nimport axios from \"axios\";\nimport { Link } from \"react-router-dom\";\nimport styled from 'styled-components';\n\nexport default function HowRoseta() {\n  const Wrap = styled.div`\n  display: flex;\n  flex-direction: row;\n  background: #f7f7f7 ;\n  max-width: 80%;\n  margin: 0 auto;\n`;\nfunction Span({ space = 20 }){\n\treturn (\n    \t<span style={{ paddingRight: space }}></span>\n    );\n}\n\n\n\n  return (\n    <div className=\"prediction_page\">\n      \n      <h1 className=\"refer-title\">\n        사용법\n        </h1>\n        <h1 className=\"title-N1\">\n       2. RoseTTAFold\n      </h1>\n      <h1 className=\"title-N1\">\n        (1) RoseTTAFold(.git) cloning\n      </h1>\n      <h1 className=\"korean-protein-expaination\">\n      git(프로그래밍 코드 버전 관리 프로그램) 설치\t\n       </h1>\n       <div className=\"code_page\">\n       $ which git\t\t//git 설치여부 확인\n        <Span></Span>\n        $ sudo apt install git\t//git 설치\n       </div>\n       \n       <h1 className=\"korean-protein-expaination\">\n       AlphaFold 클로닝\n       </h1>\n       <div className=\"code_page\">\n       $ mkdir /[filename]\n       <Span></Span>\n       $ cd /[filename]\t\t//RoseTTAFold.git를 저장하고자 하는 폴더에 접속\n       <Span></Span>\n       $ git clone https://github.com/RosettaCommons/RoseTTAFold.git\n       </div>\n       <h1 className=\"title-N1\">\n        (2) Conda environment\n      </h1>\n      <h1 className=\"korean-protein-expaination\">\n      miniconda 설치\n       </h1>\n       <div className=\"code_page\">\n       $ wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\t\n       <Span></Span>$ sh Miniconda3-latest-Linux-x86_64.sh\n       </div>\n\n       <h1 className=\"korean-protein-expaination\">\n       가상 환경 설정\n       </h1>\n       <div className=\"code_page\">\n       // RoseTTAFold\n       <Span></Span>$ conda env create -f RoseTTAFold-linux.yml\t// 가상환경 구축\n       <Span></Span>$ conda activate RoseTTAFold\t//가상환경 활성화\n       <Span></Span>(RoseTTAFold) $ conda deactivate\t//가상환경 비활성화\n\n       <Span></Span>// folding\n       <Span></Span>$ conda env create -f folding-linux.yml\n       <Span></Span>$ conda activate folding\n       <Span></Span>(folding) $ conda deactivate\n       </div>\n       <h1 className=\"title-N1\">\n        (3) Database & Tool\n      </h1>\n      <h1 className=\"korean-protein-expaination\">\n      RoseTTAFold가 클로닝 된 폴더로 접속\n       </h1>\n       <div className=\"code_page\">\n       $ cd /[filename]/RoseTTAFold\n       </div>\n       <h1 className=\"korean-protein-expaination\">\n       database를 다운로드\n       </h1>\n       <div className=\"code_page\">\n       // Uniref30\n       <Span></Span>$ wget http://wwwuser.gwdg.de/~compbiol/uniclust/2020_06/UniRef30_2020_06_hhsuite.tar.gz\n       <Span></Span>$ mkdir -p UniRef30_2020_06\n       <Span></Span>$ tar xfz UniRef30_2020_06_hhsuite.tar.gz -C ./UniRef30_2020_06\n\n       <Span></Span>// BFD\n       <Span></Span>$ wget https://bfd.mmseqs.com/bfd_metaclust_clu_complete_id30_c90_final_seq.sorted_opt.tar.gz\n       <Span></Span>$ mkdir -p bfd\n       <Span></Span>$ tar xfz bfd_metaclust_clu_complete_id30_c90_final_seq.sorted_opt.tar.gz -C ./bfd\n\n       <Span></Span>// structure templates\n       <Span></Span>$ wget https://files.ipd.uw.edu/pub/RoseTTAFold/pdb100_2021Mar03.tar.gz\n       <Span></Span>$ tar xfz pdb100_2021Mar03.tar.gz\n       </div>\n\n       <h1 className=\"korean-protein-expaination\">\n       신경망 가중치 도구 다운로드\n       </h1>\n       <div className=\"code_page\">\n       $ wget https://files.ipd.uw.edu/pub/RoseTTAFold/weights.tar.gz\n       <Span></Span>$ tar xfz weights.tar.gz\n       </div>\n\n       <h1 className=\"korean-protein-expaination\">\n       Third-party 도구 다운로드\n       </h1>\n       <div className=\"code_page\">\n       $ ./install_dependencies\n       </div>\n\n\n       <h1 className=\"title-N1\">\n        (4) PyRosetta\n      </h1>\n\n       <h1 className=\"korean-protein-expaination\">\n       라이선스 획득(https://els2.comotion.uw.edu/product/pyrosetta)\n       </h1>\n       <h1 className=\"korean-protein-expaination\">\n       사용자가 대학에 재학 또는 재직하는 것으로 가정하고 academic license를 받아 설치\n       </h1>\n       <h1 className=\"korean-protein-expaination\">\n       파이로제타 설치 (folding 가상환경)\n       </h1>\n       <div className=\"code_page\">\n       $ conda activate folding\n       <Span></Span>$ wget --http-user= --http-password= https://graylab.jhu.edu/download/PyRosetta4/archive/release/PyRosetta4.Release.python37.ubuntu/PyRosetta4.Release.python37.ubuntu.release-314.tar.bz2\n       <Span></Span>$ tar vjxf PyRosetta4.Release.python37.ubuntu.release-314.tar.bz2\n       <Span></Span>$ cd PyRosetta4.Release.python37.ubuntu.release-314/\n       <Span></Span>$ cd setup && sudo /home//miniconda3/envs/folding/bin/python3 setup.py install\n       </div>\n       \n       <h1 className=\"title-N1\">\n        (5) RoseTTAfold 실행\n      </h1>\n      <div className=\"code_page\">\n      $ cd /[filename]/RoseTTAFold\t\t// RoseTTAFold가 클로닝 된 폴더로 접속\n      <Span></Span>$ mkdir /[filename]/RoseTTAFold/input\t// input파일이 저장될 폴더 생성\n\n      <Span></Span>$ cd input\n      <Span></Span>$ ../run_pyrosetta_ver.sh [INPUT.fasta] .\n      <Span></Span>$ nohup ../run_pyrosetta_ver.sh input.fa . 2 여기&1 &\t// 백그라운드 실행\n      <Span></Span>\n      </div>\n\n\n      <h1 className=\"korean-protein-expaination\">\n      <Span></Span>*여기* 는 곧 태그 오른쪽 키를 의미함\n        </h1>\n\n        <h1 className=\"title-N1\">\n        참고\n      </h1>\n\n        <h1 className=\"korean-protein-expaination\">\n        “RoseTTAFold open-source code”, https://github.com/RosettaCommons/RoseTTAFold\n        </h1>\n        <h1 className=\"korean-protein-expaination\">\n        “2021-Accurate prediction of protein structures and interactions using a three-track neural network”, https://www.science.org/doi/10.1126/science.abj8754\n        </h1>\n        <h1 className=\"korean-protein-expaination\">\n        “구글인력/컴퓨팅 없이 알파폴드2 재현한 로제타폴드, 어떻게 가능했나?”(Ai타임스기사),\nhttps://www.aitimes.com/news/articleView.html?idxno=140110\n        </h1>\n        <h1 className=\"korean-protein-expaination\">\n        “[초심자를 위한 생물학+정보학] 로제타폴드의 설치와 사용”,\nhttps://www.ibric.org/myboard/read.php?id=339786&Board=news&rtpath=main\n        </h1>\n        <h1 className=\"korean-protein-expaination\">\n        CNN\n        </h1>\n        <h1 className=\"korean-protein-expaination\">\n        <Span></Span>“1989-Backpropagation applied to handwritten zip code recognition”\n        </h1>\n        <h1 className=\"korean-protein-expaination\">\n        <Span></Span>“2003-Hierarchical Neural Networks for Image Interpretation”\n        </h1>\n        <h1 className=\"korean-protein-expaination\">\n        <Span></Span>“2003-Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis”\n        </h1>\n        <h1 className=\"korean-protein-expaination\">\n        “Convolutional Neural Network(CNN)”,\nhttps://sonsnotation.blogspot.com/2020/11/7-convolutional-neural-networkcnn.html\n        </h1>\n        <h1 className=\"korean-protein-expaination\">\n        “CNN 설명”,\nhttps://rubber-tree.tistory.com/entry/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%AA%A8%EB%8D%B8-CNN-Convolutional-Neural-Network-%EC%84%A4%EB%AA%85\n        </h1>\n        <h1 className=\"korean-protein-expaination\">\n        “합성곱신경망”, https://excelsior-cjh.tistory.com/79\n        </h1>\n        <h1 className=\"korean-protein-expaination\">\n        “CNN, Convolutional Neural Network 요약”, http://taewan.kim/post/cnn/\n        </h1>\n       \n\n\n\n    </div>\n  );\n}","/Users/hayungyoo/project/konfold_front/src/pages/Reference/Pred_skills.jsx",["172","173","174","175","176","177"],[],"import React, { useEffect, useState } from \"react\";\nimport axios from \"axios\";\nimport { Link } from \"react-router-dom\";\nimport styled from 'styled-components';\nimport NavBar_Prediction from './NavBar_Prediction.js';\n\n\nexport default function Pred_skills() {\n    const Wrap = styled.div`\n  display: flex;\n  flex-direction: row;\n  background: #f7f7f7 ;\n  max-width: 80%;\n  margin: 0 auto;\n`;\nfunction Span({ space = 20 }){\n\treturn (\n    \t<span style={{ paddingRight: space }}></span>\n    );\n}\n\nreturn (\n    <div className=\"prediction_page\">\n        <NavBar_Prediction/>\n        <h1 className=\"refer-title\">\n        단백질 구조 예측 AI\n        </h1>\n        <h1 className=\"title-N1\">\n        3. 주요 기술\n      </h1>\n      <h1 className=\"title-N1\">\n      (1) CNN(합성곱 신경망, Convolutional Neural Networks, ConvNet)\n      </h1>\n\n      <h1 className=\"korean-protein-expaination\">\n      <Span /><Span />\n      Image를 분류하기 위해 1989년 Yann LeCun의 논문에서 고안된 알고리즘으로 Fully Connected Layer만으로 구성된 신경망의 한계를 보완한다. Image는 수많은 픽셀로 이루어져 있는 Matrix이며 픽셀은 0~255 사이의 숫자로 표현된다. 이러한 matrix를 일자로 쭉 펼쳐 실수로 구성된 vector를 input으로 하여 딥러닝 모델을 만들 수 있다.\n       </h1>\n       <div>\n        <img className=\"process_img\" alt=\"role\" src=\"/img/cnnLayer.png\" />\n      </div>\n      <h1 className=\"korean-protein-expaination\">\n      <Span /><Span />\n      하지만 이 경우 하나의 픽셀에 해당하는 feature의 수가 많아지며, hidden node의 layer가 많아질수록 학습될 파라미터가 몇배로 늘어나게 된다. 결국 모델의 사이즈가 커져 학습시간의 효율성이 떨어진다. 또한 matrix를 vector로 변환하는 과정에서 이미지의 공간정보가 유실된다. 따라서 기하학적 특징(topology)를 학습하지 않게 되며 다양한 변형이 존재하는 이미지의 학습을 위해서는 충분히 많은 데이터가 필요해진다. CNN은 이를 보완하여 Classification(분류)단계 이전에 feature extraction(특징추출) 단계를 각 레이어의 입출력 데이터의 형상, 즉 2D 공간 정보를 유지한 채 이미지를 학습하는 모델이다.\n       </h1>\n       <div>\n        <img className=\"process_img\" alt=\"role\" src=\"/img/featureExtraction.png\" />\n      </div>\n\n      <h1 className=\"title-N1\">\n      1. Convolution Layer\n      </h1>\n      <h1 className=\"korean-protein-expaination\">\n      <Span /><Span />\n      이미지의 특징을 추출(feature extraction)하는 layer로, 합성곱 연산을 사용한다.\n       </h1>\n       <div>\n        <img className=\"process_img\" alt=\"role\" src=\"/img/convolutionLayer.png\" />\n      </div>\n\n      <h1 className=\"title-N1\">\n      2. Pooling Layer\n      </h1>\n      <h1 className=\"korean-protein-expaination\">\n      <Span /><Span />\n      이미지 matrix의 크기를 줄이면서 주요 feature를 강조하는 layer이다. 학습 데이터의 크기를 줄이면서 학습 데이터가 이미지의 특징을 충분히 반영할 수 있도록 한다. 대부분의 CNN에서는 최댓값을 선택하는 Max Pooling을 사용한다. 인간이 이미지를 볼 때, 시신경에 들어온 신호 중 강한 신호만 살아남고 나머지는 무시한다는 사실을 반영한 것이다.\n       </h1>\n       <div>\n        <img className=\"process_img\" alt=\"role\" src=\"/img/poolingLayer.png\" />\n      </div>\n      <h1 className=\"title-N1\">\n      (2) Transformer\n      </h1>\n      <h1 className=\"korean-protein-expaination\">\n      <Span /><Span />\n      2017년 NIPS를 통해 발표된 모델로, NLP(Natural Language Processing, 자연어처리) 분야에서 ‘Attention’이라는 메커니즘을 활용해 만든 번역기로부터 처음 등장했다. 현재 단어 vector를 input으로 사용하는 NLP 분야부터 이미지 feature vector를 input으로 하는 CV(Computer Vision, 컴퓨터비전)까지 다양하게 사용된다. \nAlphaFold와 RoseTTAFold는 바로 CNN 대신 이 기술을 사용한다. CNN에서는 바로 옆 픽셀의 정보만 학습에 영향을 주는 반면 Attention의 경우 멀리 떨어진 곳의 정보도 활용하며, 연관도에 따라 정보를 가져오는 양을 조절할 수 있다. 이것은 서로 멀리 떨어진 잔기들도 서로 관련이 있는 단백질 구조를 예측하는 데에 효과적이다.\n       </h1>\n       <div>\n        <img className=\"process_img\" alt=\"role\" src=\"/img/skills_transformer.png\" />\n      </div>\n      <div>\n        <img className=\"process_img\" alt=\"role\" src=\"/img/skills_block.png\" />\n      </div>\n\n\n\n\n    </div>\n)\n}","/Users/hayungyoo/project/konfold_front/src/pages/Reference/NavBar_Prediction.js",["178"],[],"import React, { useState } from 'react';\n\nconst NavBar_Prediction = () => {\n    function Span({ space = 20 }){\n        return (\n            <span style={{ paddingRight: space }}></span>\n        );\n    }\n    return (\n\n        <nav className=\"prediction_nav\">\n            <Span></Span>\n           <li>\n            <a href=\"/Refer/Prediction/*\" className=\"pred_menu\">\n                1. 단백질 구조 예측 AI의 의의\n            </a>\n          </li>\n\n          <li>\n            <a href=\"/Refer/Prediction/mechanism/*\" className=\"pred_menu\">\n                2. 단백질 구조 예측 AI 메커니즘\n            </a>\n          </li>\n\n          <li>\n            <a href=\"/Refer/Prediction/skills/*\" className=\"pred_menu\">\n                3. 주요 기술\n            </a>\n          </li>\n\n          <li>\n            <a href=\"/Refer/Prediction/ability/*\" className=\"pred_menu\">\n                4. 성능확인\n            </a>\n          </li>\n          <Span></Span>\n        </nav>\n    )\n}\nexport default NavBar_Prediction;",{"ruleId":"179","severity":1,"message":"180","line":1,"column":17,"nodeType":"181","messageId":"182","endLine":1,"endColumn":26},{"ruleId":"183","severity":1,"message":"184","line":35,"column":66,"nodeType":"185","messageId":"186","endLine":35,"endColumn":78},{"ruleId":"183","severity":1,"message":"187","line":36,"column":64,"nodeType":"185","messageId":"186","endLine":36,"endColumn":79},{"ruleId":"183","severity":1,"message":"188","line":37,"column":63,"nodeType":"185","messageId":"186","endLine":37,"endColumn":77},{"ruleId":"179","severity":1,"message":"189","line":6,"column":11,"nodeType":"181","messageId":"182","endLine":6,"endColumn":18},{"ruleId":"179","severity":1,"message":"190","line":9,"column":11,"nodeType":"181","messageId":"182","endLine":9,"endColumn":21},{"ruleId":"191","severity":1,"message":"192","line":11,"column":9,"nodeType":"181","messageId":"193","endLine":11,"endColumn":15},{"ruleId":"179","severity":1,"message":"194","line":2,"column":8,"nodeType":"181","messageId":"182","endLine":2,"endColumn":13},{"ruleId":"179","severity":1,"message":"195","line":3,"column":10,"nodeType":"181","messageId":"182","endLine":3,"endColumn":14},{"ruleId":"179","severity":1,"message":"196","line":4,"column":10,"nodeType":"181","messageId":"182","endLine":4,"endColumn":19},{"ruleId":"179","severity":1,"message":"197","line":6,"column":8,"nodeType":"181","messageId":"182","endLine":6,"endColumn":18},{"ruleId":"179","severity":1,"message":"198","line":14,"column":10,"nodeType":"181","messageId":"182","endLine":14,"endColumn":25},{"ruleId":"179","severity":1,"message":"194","line":2,"column":8,"nodeType":"181","messageId":"182","endLine":2,"endColumn":13},{"ruleId":"179","severity":1,"message":"197","line":4,"column":8,"nodeType":"181","messageId":"182","endLine":4,"endColumn":18},{"ruleId":"179","severity":1,"message":"199","line":10,"column":10,"nodeType":"181","messageId":"182","endLine":10,"endColumn":21},{"ruleId":"179","severity":1,"message":"196","line":1,"column":17,"nodeType":"181","messageId":"182","endLine":1,"endColumn":26},{"ruleId":"179","severity":1,"message":"200","line":1,"column":28,"nodeType":"181","messageId":"182","endLine":1,"endColumn":36},{"ruleId":"179","severity":1,"message":"194","line":2,"column":8,"nodeType":"181","messageId":"182","endLine":2,"endColumn":13},{"ruleId":"179","severity":1,"message":"195","line":3,"column":10,"nodeType":"181","messageId":"182","endLine":3,"endColumn":14},{"ruleId":"179","severity":1,"message":"201","line":9,"column":11,"nodeType":"181","messageId":"182","endLine":9,"endColumn":15},{"ruleId":"179","severity":1,"message":"202","line":16,"column":14,"nodeType":"181","messageId":"182","endLine":16,"endColumn":18},{"ruleId":"183","severity":1,"message":"203","line":24,"column":13,"nodeType":"185","messageId":"186","endLine":24,"endColumn":33},{"ruleId":"179","severity":1,"message":"180","line":1,"column":28,"nodeType":"181","messageId":"182","endLine":1,"endColumn":37},{"ruleId":"179","severity":1,"message":"204","line":5,"column":8,"nodeType":"181","messageId":"182","endLine":5,"endColumn":14},{"ruleId":"179","severity":1,"message":"205","line":6,"column":8,"nodeType":"181","messageId":"182","endLine":6,"endColumn":14},{"ruleId":"179","severity":1,"message":"197","line":7,"column":8,"nodeType":"181","messageId":"182","endLine":7,"endColumn":18},{"ruleId":"179","severity":1,"message":"206","line":13,"column":10,"nodeType":"181","messageId":"182","endLine":13,"endColumn":17},{"ruleId":"179","severity":1,"message":"207","line":14,"column":10,"nodeType":"181","messageId":"182","endLine":14,"endColumn":14},{"ruleId":"179","severity":1,"message":"200","line":1,"column":17,"nodeType":"181","messageId":"182","endLine":1,"endColumn":25},{"ruleId":"179","severity":1,"message":"201","line":8,"column":9,"nodeType":"181","messageId":"182","endLine":8,"endColumn":13},{"ruleId":"179","severity":1,"message":"202","line":15,"column":12,"nodeType":"181","messageId":"182","endLine":15,"endColumn":16},{"ruleId":"179","severity":1,"message":"208","line":22,"column":7,"nodeType":"181","messageId":"182","endLine":22,"endColumn":11},{"ruleId":"179","severity":1,"message":"209","line":23,"column":7,"nodeType":"181","messageId":"182","endLine":23,"endColumn":10},{"ruleId":"179","severity":1,"message":"196","line":1,"column":17,"nodeType":"181","messageId":"182","endLine":1,"endColumn":26},{"ruleId":"179","severity":1,"message":"200","line":1,"column":28,"nodeType":"181","messageId":"182","endLine":1,"endColumn":36},{"ruleId":"179","severity":1,"message":"194","line":2,"column":8,"nodeType":"181","messageId":"182","endLine":2,"endColumn":13},{"ruleId":"179","severity":1,"message":"195","line":3,"column":10,"nodeType":"181","messageId":"182","endLine":3,"endColumn":14},{"ruleId":"179","severity":1,"message":"202","line":16,"column":14,"nodeType":"181","messageId":"182","endLine":16,"endColumn":18},{"ruleId":"179","severity":1,"message":"196","line":1,"column":17,"nodeType":"181","messageId":"182","endLine":1,"endColumn":26},{"ruleId":"179","severity":1,"message":"200","line":1,"column":28,"nodeType":"181","messageId":"182","endLine":1,"endColumn":36},{"ruleId":"179","severity":1,"message":"194","line":2,"column":8,"nodeType":"181","messageId":"182","endLine":2,"endColumn":13},{"ruleId":"179","severity":1,"message":"195","line":3,"column":10,"nodeType":"181","messageId":"182","endLine":3,"endColumn":14},{"ruleId":"179","severity":1,"message":"205","line":4,"column":8,"nodeType":"181","messageId":"182","endLine":4,"endColumn":14},{"ruleId":"179","severity":1,"message":"210","line":4,"column":18,"nodeType":"181","messageId":"182","endLine":4,"endColumn":27},{"ruleId":"211","severity":1,"message":"212","line":10,"column":7,"nodeType":"185","endLine":10,"endColumn":63},{"ruleId":"179","severity":1,"message":"196","line":1,"column":17,"nodeType":"181","messageId":"182","endLine":1,"endColumn":26},{"ruleId":"179","severity":1,"message":"200","line":1,"column":28,"nodeType":"181","messageId":"182","endLine":1,"endColumn":36},{"ruleId":"179","severity":1,"message":"194","line":2,"column":8,"nodeType":"181","messageId":"182","endLine":2,"endColumn":13},{"ruleId":"179","severity":1,"message":"195","line":3,"column":10,"nodeType":"181","messageId":"182","endLine":3,"endColumn":14},{"ruleId":"213","severity":1,"message":"214","line":67,"column":21,"nodeType":"215","messageId":"216","endLine":69,"endColumn":8},{"ruleId":"213","severity":1,"message":"214","line":69,"column":21,"nodeType":"215","messageId":"216","endLine":71,"endColumn":8},{"ruleId":"213","severity":1,"message":"214","line":78,"column":34,"nodeType":"215","messageId":"216","endLine":80,"endColumn":7},{"ruleId":"213","severity":1,"message":"214","line":82,"column":20,"nodeType":"215","messageId":"216","endLine":84,"endColumn":7},{"ruleId":"213","severity":1,"message":"214","line":86,"column":20,"nodeType":"215","messageId":"216","endLine":88,"endColumn":7},{"ruleId":"213","severity":1,"message":"214","line":92,"column":20,"nodeType":"215","messageId":"216","endLine":94,"endColumn":7},{"ruleId":"213","severity":1,"message":"214","line":96,"column":20,"nodeType":"215","messageId":"216","endLine":98,"endColumn":7},{"ruleId":"213","severity":1,"message":"214","line":122,"column":21,"nodeType":"215","messageId":"216","endLine":124,"endColumn":8},{"ruleId":"213","severity":1,"message":"214","line":148,"column":35,"nodeType":"215","messageId":"216","endLine":150,"endColumn":8},{"ruleId":"213","severity":1,"message":"214","line":151,"column":21,"nodeType":"215","messageId":"216","endLine":152,"endColumn":8},{"ruleId":"213","severity":1,"message":"214","line":153,"column":21,"nodeType":"215","messageId":"216","endLine":154,"endColumn":8},{"ruleId":"213","severity":1,"message":"214","line":200,"column":23,"nodeType":"215","messageId":"216","endLine":201,"endColumn":7},{"ruleId":"179","severity":1,"message":"196","line":1,"column":17,"nodeType":"181","messageId":"182","endLine":1,"endColumn":26},{"ruleId":"179","severity":1,"message":"200","line":1,"column":28,"nodeType":"181","messageId":"182","endLine":1,"endColumn":36},{"ruleId":"183","severity":1,"message":"203","line":25,"column":13,"nodeType":"185","messageId":"186","endLine":25,"endColumn":33},{"ruleId":"179","severity":1,"message":"196","line":1,"column":17,"nodeType":"181","messageId":"182","endLine":1,"endColumn":26},{"ruleId":"179","severity":1,"message":"200","line":1,"column":28,"nodeType":"181","messageId":"182","endLine":1,"endColumn":36},{"ruleId":"179","severity":1,"message":"194","line":2,"column":8,"nodeType":"181","messageId":"182","endLine":2,"endColumn":13},{"ruleId":"179","severity":1,"message":"195","line":3,"column":10,"nodeType":"181","messageId":"182","endLine":3,"endColumn":14},{"ruleId":"183","severity":1,"message":"203","line":24,"column":7,"nodeType":"185","messageId":"186","endLine":24,"endColumn":27},{"ruleId":"179","severity":1,"message":"196","line":1,"column":17,"nodeType":"181","messageId":"182","endLine":1,"endColumn":26},{"ruleId":"179","severity":1,"message":"200","line":1,"column":28,"nodeType":"181","messageId":"182","endLine":1,"endColumn":36},{"ruleId":"179","severity":1,"message":"194","line":2,"column":8,"nodeType":"181","messageId":"182","endLine":2,"endColumn":13},{"ruleId":"179","severity":1,"message":"195","line":3,"column":10,"nodeType":"181","messageId":"182","endLine":3,"endColumn":14},{"ruleId":"179","severity":1,"message":"201","line":7,"column":9,"nodeType":"181","messageId":"182","endLine":7,"endColumn":13},{"ruleId":"213","severity":1,"message":"214","line":67,"column":35,"nodeType":"215","messageId":"216","endLine":69,"endColumn":8},{"ruleId":"213","severity":1,"message":"214","line":73,"column":21,"nodeType":"215","messageId":"216","endLine":74,"endColumn":8},{"ruleId":"213","severity":1,"message":"214","line":90,"column":35,"nodeType":"215","messageId":"216","endLine":92,"endColumn":8},{"ruleId":"213","severity":1,"message":"214","line":96,"column":21,"nodeType":"215","messageId":"216","endLine":97,"endColumn":8},{"ruleId":"213","severity":1,"message":"214","line":101,"column":21,"nodeType":"215","messageId":"216","endLine":102,"endColumn":8},{"ruleId":"179","severity":1,"message":"196","line":1,"column":17,"nodeType":"181","messageId":"182","endLine":1,"endColumn":26},{"ruleId":"179","severity":1,"message":"200","line":1,"column":28,"nodeType":"181","messageId":"182","endLine":1,"endColumn":36},{"ruleId":"179","severity":1,"message":"194","line":2,"column":8,"nodeType":"181","messageId":"182","endLine":2,"endColumn":13},{"ruleId":"179","severity":1,"message":"195","line":3,"column":10,"nodeType":"181","messageId":"182","endLine":3,"endColumn":14},{"ruleId":"179","severity":1,"message":"201","line":9,"column":11,"nodeType":"181","messageId":"182","endLine":9,"endColumn":15},{"ruleId":"183","severity":1,"message":"203","line":24,"column":9,"nodeType":"185","messageId":"186","endLine":24,"endColumn":29},{"ruleId":"179","severity":1,"message":"200","line":1,"column":17,"nodeType":"181","messageId":"182","endLine":1,"endColumn":25},"no-unused-vars","'Component' is defined but never used.","Identifier","unusedVar","react/jsx-pascal-case","Imported JSX component Pred_mech must be in PascalCase or SCREAMING_SNAKE_CASE","JSXOpeningElement","usePascalOrSnakeCase","Imported JSX component Pred_ability must be in PascalCase or SCREAMING_SNAKE_CASE","Imported JSX component Pred_skills must be in PascalCase or SCREAMING_SNAKE_CASE","'menuLst' is assigned a value but never used.","'mouseEvent' is assigned a value but never used.","no-const-assign","'change' is constant.","const","'axios' is defined but never used.","'Link' is defined but never used.","'useEffect' is defined but never used.","'ClipLoader' is defined but never used.","'proteinSearchID' is assigned a value but never used.","'pdb_predict' is assigned a value but never used.","'useState' is defined but never used.","'Wrap' is assigned a value but never used.","'Span' is defined but never used.","Imported JSX component NavBar_Prediction must be in PascalCase or SCREAMING_SNAKE_CASE","'Search' is defined but never used.","'styled' is defined but never used.","'loading' is assigned a value but never used.","'ptid' is assigned a value but never used.","'blob' is assigned a value but never used.","'url' is assigned a value but never used.","'keyframes' is defined but never used.","jsx-a11y/alt-text","img elements must have an alt prop, either with meaningful text, or an empty string for decorative images.","react/jsx-no-comment-textnodes","Comments inside children section of tag should be placed inside braces","JSXText","putCommentInBraces"]